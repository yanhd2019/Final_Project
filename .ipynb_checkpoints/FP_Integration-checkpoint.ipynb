{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58c1c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c4c83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca3e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b545b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c280954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "openai.api_key = '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'\n",
    "API_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78cd8467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtts  # For text-to-speech\n",
    "import moviepy.editor as mpy  # For video processing\n",
    "import cv2  # For image processing\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from gtts import gTTS\n",
    "from moviepy.editor import ImageClip, AudioFileClip\n",
    "from moviepy.editor import concatenate_videoclips, CompositeVideoClip, \\\n",
    "ImageClip, ColorClip, AudioFileClip, vfx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bef09fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbd1952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_input():\n",
    "    \"\"\"\n",
    "    Captures user input on an economics topic.\n",
    "    Returns:\n",
    "        str: The user's input.\n",
    "    \"\"\"\n",
    "    prompt = \"Please enter your question or topic related to economics: \"\n",
    "    user_input = input(prompt)\n",
    "    return user_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84201084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_genapi(user_input, API_key = API_key):\n",
    "    \"\"\"\n",
    "    Sends a query to GenAPI (GPT-4 Turbo) to explain an economic concept in a structured format.\n",
    "    The response may include Python code for figures or prompts for the DALL-E API (ImageAPI).\n",
    "\n",
    "    Args:\n",
    "        user_input (str): The user's input or question about economics.\n",
    "        API_key (str): The API key for OpenAI.\n",
    "\n",
    "    Returns:\n",
    "        str: The raw response from the GenAPI.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        openai.api_key = API_key\n",
    "        client = OpenAI(api_key=API_key)\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-1106-preview\",  # GPT-4 Turbo 1106 model\n",
    "            messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\"You are an economic tutor. Explain economic concepts or answer economic questions\" \n",
    "                            \"in using figures and explainations for each part of the concept or question. The \"\n",
    "                            \"figures should be labeled [Figure - concept name] and the explanations should be labeled [Explaination - concept name]\"\n",
    "                            \"at the start. All figures in the response should be displayed as either Python code for figures \"\n",
    "                            \"(graphs/tables/matrix/equations)\"\n",
    "                            #\" or a specific prompt for the DALL-E API (ImageAPI) if no suitable image can be coded\"\n",
    "                            \". Each explaination should refer to each and all of \"\n",
    "                            \"the figures and real-life scenarios. You can have multiple [Figure] and [Explaination]. Respond with 'This is not Economic related. \"\n",
    "                            \"Ask me anything about Economics instead!' if no economic concepts are mentioned.\"\n",
    "                            \"have the response displayed in the order of [figure - a], [explaination - a], [figure - b], [explaination - b], etc.\")\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_input\n",
    "            }\n",
    "        ],\n",
    "            temperature=1,\n",
    "            max_tokens=1000,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "\n",
    "        # Extracting the response text\n",
    "        assistant_message = response.choices[0].message.content\n",
    "\n",
    "        return assistant_message\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Example usage\n",
    "# test = query_genapi(\"demand and supply\", \"your-api-key\")\n",
    "# print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0095bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = query_genapi(\"demand and supply, explain it with multiple graphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386fc206",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8451be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_response(response):\n",
    "    \"\"\"\n",
    "    Segments the response into separate lists for figures and explanations.\n",
    "\n",
    "    Args:\n",
    "        response (str): The raw response string from GenAPI.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two lists, one containing all figure scripts and the other all explanations.\n",
    "    \"\"\"\n",
    "    def extract_figure_code(text):\n",
    "        \"\"\"\n",
    "        Extracts Python code for a figure from the given text.\n",
    "        Args:\n",
    "            text (str): Text containing the figure code.\n",
    "\n",
    "        Returns:\n",
    "            str: Extracted Python code.\n",
    "        \"\"\"\n",
    "        if \"```python\" in text:\n",
    "            code = text.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "            return code\n",
    "        return \"\"\n",
    "\n",
    "    figure_codes = []\n",
    "    explanations = []\n",
    "\n",
    "    # Splitting the response into segments based on [Figure] and [Explaination] tags\n",
    "    segments = response.split('[Figure - ')\n",
    "    for segment in segments[1:]:  # Skip the first split as it's before the first [Figure]\n",
    "        if '[Explaination - ' in segment:\n",
    "            figure_part, explanation_part = segment.split('[Explaination - ', 1)\n",
    "            figure_code = extract_figure_code(figure_part)\n",
    "            explanation = explanation_part.split(']\\n', 1)[1].strip() if ']\\n' in explanation_part else explanation_part.strip()\n",
    "\n",
    "            figure_codes.append(figure_code)\n",
    "            explanations.append(explanation)\n",
    "\n",
    "    return figure_codes, explanations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c9b8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "code, explaination = segment_response(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85212305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def process_figures(figure_codes, folder_path='./figures'):\n",
    "    \"\"\"\n",
    "    Processes figure codes by executing Python code to generate and save graphs.\n",
    "    Creates the 'figures' folder if it does not exist.\n",
    "\n",
    "    Args:\n",
    "        figure_codes (list): List of figure codes (Python code for graphs).\n",
    "        folder_path (str): Path to the folder where images will be saved.\n",
    "\n",
    "    Returns:\n",
    "        list: Paths to the saved figure images.\n",
    "    \"\"\"\n",
    "    def save_plot(figure_code, figure_path):\n",
    "        \"\"\" Executes Python code for plotting and saves the plot. \"\"\"\n",
    "        try:\n",
    "            # Create a separate namespace for executing the figure code\n",
    "            namespace = {}\n",
    "            exec(figure_code, globals(), namespace)\n",
    "            plt.savefig(figure_path)\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating plot: {e}\")\n",
    "\n",
    "    # Check if the folder exists, and create it if it doesn't\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    figure_paths = []\n",
    "    for i, figure_code in enumerate(figure_codes):\n",
    "        # Remove plt.show() from the code\n",
    "        modified_figure_code = figure_code.replace('plt.show()', '')\n",
    "        figure_path = os.path.join(folder_path, f\"Figure{i+1}.png\")\n",
    "        save_plot(modified_figure_code, figure_path)\n",
    "        figure_paths.append(figure_path)\n",
    "\n",
    "    return figure_paths\n",
    "\n",
    "# Example Usage:\n",
    "# figure_codes = [...]  # List of figure codes (Python code for graphs)\n",
    "# figure_paths = process_figures(figure_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b285145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_paths = process_figures(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe33a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59b95ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio_explanations(explanations, folder_path='./audios'):\n",
    "    \"\"\"\n",
    "    Generates audio files from the list of explanations.\n",
    "\n",
    "    Args:\n",
    "        explanations (list): A list of explanation texts.\n",
    "        folder_path (str): Path to the folder where audio files will be saved.\n",
    "\n",
    "    Returns:\n",
    "        list: Paths to the saved audio files.\n",
    "    \"\"\"\n",
    "    # Check if the folder exists, and create it if it doesn't\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    audio_paths = []\n",
    "    for i, explanation in enumerate(explanations):\n",
    "        audio_path = os.path.join(folder_path, f\"Explanation{i+1}.mp3\")\n",
    "        tts = gTTS(text=explanation, lang='en')\n",
    "        tts.save(audio_path)\n",
    "        audio_paths.append(audio_path)\n",
    "\n",
    "    return audio_paths\n",
    "\n",
    "# Example Usage:\n",
    "# explanations = [...]  # List of explanation texts\n",
    "# audio_paths = generate_audio_explanations(explanations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1905b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_paths = generate_audio_explanations(explaination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3bac155",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c41cccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_clips(figure_paths, audio_paths, folder_path='./clips'):\n",
    "    \"\"\"\n",
    "    Creates and saves video clips by combining each figure with its corresponding audio explanation.\n",
    "    Saves the clips to a specified folder.\n",
    "\n",
    "    Args:\n",
    "        figure_paths (list): A list of paths to figure images.\n",
    "        audio_paths (list): A list of paths to audio files.\n",
    "        folder_path (str): Path to the folder where video clips will be saved.\n",
    "\n",
    "    Returns:\n",
    "        list: Paths to the saved video clips.\n",
    "    \"\"\"\n",
    "    # Check if the folder exists, and create it if it doesn't\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    video_clip_paths = []\n",
    "    for i, (figure_path, audio_path) in enumerate(zip(figure_paths, audio_paths)):\n",
    "        # Create an image clip\n",
    "        image_clip = ImageClip(figure_path)\n",
    "\n",
    "        # Attach audio to the image clip\n",
    "        audio_clip = AudioFileClip(audio_path)\n",
    "        video_clip = image_clip.set_audio(audio_clip).set_duration(audio_clip.duration)\n",
    "\n",
    "        # Save the video clip\n",
    "        video_clip_path = os.path.join(folder_path, f\"Clip{i+1}.mp4\")\n",
    "        video_clip.write_videofile(video_clip_path, codec=\"libx264\", fps=24)\n",
    "        video_clip_paths.append(video_clip_path)\n",
    "\n",
    "    return video_clip_paths\n",
    "\n",
    "# Example Usage:\n",
    "# figure_paths = [...]  # Paths to figure images\n",
    "# audio_paths = [...]   # Paths to audio files\n",
    "# video_clip_paths = create_video_clips(figure_paths, audio_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d2ecede",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clips = create_video_clips(figure_paths, audio_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cd1303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b3fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "509962c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_and_save_video(video_clips, final_video_path='./results/finalvideo.mp4', background_path=None, bg_color='black', bg_size=(1920, 1080), clip_size=(1280, 720)):\n",
    "    \"\"\"\n",
    "    Combines video clips into a single video and saves it.\n",
    "    Resizes video clips to a fixed size and ensures RGB format.\n",
    "\n",
    "    Args:\n",
    "        video_clips (list): List of video clip objects.\n",
    "        final_video_path (str): Path where the final video will be saved.\n",
    "        background_path (str, optional): Path to a background image file.\n",
    "        bg_color (str): Background color if no background image is used.\n",
    "        bg_size (tuple): Size of the background (width, height).\n",
    "        clip_size (tuple): Fixed size for all video clips (width, height).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    def resize_and_convert_clip(clip):\n",
    "        \"\"\" Resize and convert the clip to RGB format if necessary. \"\"\"\n",
    "        # Resize the clip\n",
    "        clip = clip.resize(clip_size)\n",
    "        # Convert to RGB if it's not a mask and not already RGB\n",
    "        if not clip.ismask and clip.img.ndim != 3:\n",
    "            clip = clip.fx(vfx.colorx, 1)\n",
    "        return clip\n",
    "\n",
    "    def create_background_clip(duration):\n",
    "        \"\"\" Creates a background clip, either from an image or a color. \"\"\"\n",
    "        if background_path:\n",
    "            bg_clip = ImageClip(background_path, duration=duration).resize(bg_size)\n",
    "            # Convert to RGB if necessary\n",
    "            if bg_clip.img.ndim != 3:\n",
    "                bg_clip = bg_clip.fx(vfx.colorx, 1)\n",
    "        else:\n",
    "            # Create a color clip with the specified size and color\n",
    "            bg_clip = ColorClip(size=bg_size, color=bg_color, duration=duration)\n",
    "        return bg_clip\n",
    "\n",
    "    # Resize and convert clips to RGB format\n",
    "    processed_clips = [resize_and_convert_clip(clip) for clip in video_clips]\n",
    "\n",
    "    # Debug: Print properties of each clip\n",
    "    for i, clip in enumerate(processed_clips):\n",
    "        print(f\"Clip {i}: size={clip.size}, ismask={clip.ismask}, ndim={clip.img.ndim if hasattr(clip, 'img') else 'N/A'}\")\n",
    "\n",
    "    # Calculate total duration of the final video\n",
    "    total_duration = sum(clip.duration for clip in processed_clips)\n",
    "\n",
    "    # Create the background clip\n",
    "    #background_clip = create_background_clip(total_duration)\n",
    "\n",
    "    # Combine each clip with the background\n",
    "#     composited_clips = [CompositeVideoClip([background_clip, clip.set_position(\"center\")]) for clip in processed_clips]\n",
    "\n",
    "    # Concatenate all clips and write the video file\n",
    "#     final_clip = concatenate_videoclips(composited_clips, method='compose')\n",
    "    final_clip = concatenate_videoclips(processed_clips, method='compose')\n",
    "    final_clip.write_videofile(final_video_path, codec='libx264', fps=24, verbose=True)\n",
    "\n",
    "# Example Usage\n",
    "# final_video_path = './final_video.mp4'\n",
    "# combine_and_save_video(video_clips, final_video_path, background_path=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "543dbd79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_video_path = './results/final_video.mp4'\n",
    "background_path = './bg_image.png'\n",
    "combine_and_save_video(video_clips, final_video_path, background_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebaf5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e4633e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
